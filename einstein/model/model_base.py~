import lasagne as l
import theano as T
import theano.tensor as TT
import einstein as e
import einstein.data_structure as d


class Model():
    """
    This class takes care of the modelling of system.
    """
    def __init__(self, model_params, n_times_steps, cost_f=None,):
        """
        This function is responsible for creating a model based on the dictionary
        :param model_params: a ordered dictionary type that contains information of layers.
        First item in dictionary is the first layer. Second item in dictionary is the second layer.
        :type model_params: collections.OrderedDict
        :return: None
        :rtype: None
        """
        # Get input as internal representation
        self.model_params = model_params
        print self.model_params
        self.cost_f = cost_f

        # Initialize symbolic parameters
        self.__init_symb()

        # Initialize parameters needed for later calculation
        self.current_layer = None
        self.previous_layer = None

        # Initialize communication socket
        self.socket = e.serial.socket.SocketServer()
        self.ring_buffer = d.RingBuffer(size=n_time_steps + 1) # need reward of next step for training

        # Build the model
        self.__build_model()
        self.__build_cost_function()
        self.__build_training_rule()
        self.__build_functions()



    def __init_symb(self):
        """
        Initialize the symbolic variables of the model (e.g. input and output)
        :return:
        """
        self.input = TT.tensor3('input')
        self.target_output = TT.tensor3('target_output')

    def __build_model(self):
        """
        Use parameters of the layers to build model.
        :return:
        """
        # Parameters for storing all layers
        self.layers = []
        # Instantiate all layer
        for layer, params in self.model_params:

            # Test whether this is the first layer or not
            if None == self.previous_layer:
                self.current_layer = layer(**params)
            else:
                self.current_layer = layer(input_layer=self.previous_layer, **params)

            # Append current layer into layer list
            self.layers.append(self.current_layer)
            self.previous_layer = self.current_layer
            raw_input()

    def __build_cost_function(self):
        if self.cost_f == None:
            self.cost = T.mean((self.layers[-1].get_output(self.input)[:, :, :]
                    - self.target_output[:, :, :])**2)
        else:
            self.cost = self.cost_f(self.layers[-1].get_output(self.input)[:, :, :], self.target_output[:, :, :])

    def __build_training_rule(self):
        # Use NAG for training
        all_params = l.layers.get_all_params(self.layers[-1])
        self.updates = l.updates.nesterov_momentum(self.cost, all_params, LEARNING_RATE)

    def __build_functions(self):
        self._train = T.function([self.input, self.target_output], self.cost, updates=self.updates)
        self.y_pred_reward = T.function([input], self.layers[-1].get_output(input))
        self.compute_cost = T.function([input, self.target_output], self.cost)

    def train(self):
        ring_buffer = RingBuffer(size=N_TIME_STEPS + 1) # need reward of next step for training

if __name__ == "__main__":
    import numpy as np
    from data_structure import RingBuffer
    from serial.socket import SocketServer


    # Start of sequence
    START = 1

    # End of Sequence
    END = 20

    # Points to be evaluated
    POINTS = 1000

    # Number of transmitted variables
    N_TRANS = 5

    # Input features
    N_INPUT_FEATURES = 4

    # Output Features
    N_OUTPUT_FEATURES = 1

    # Length of each input sequence of data
    N_TIME_STEPS = 12  # in cart pole balancing case, x, x_dot, theta, theta_dot and reward are inputs


    # Number of units in the hidden (recurrent) layer
    N_HIDDEN = 20

    # This means how many sequences you would like to input to the sequence.
    N_BATCH = 1

    # Delay used to generate artificial training data
    DELAY = 1

    # SGD learning rate
    LEARNING_RATE = 1e-6

    # Number of iterations to train the net
    N_ITERATIONS = 1000000

    # Forget rate
    FORGET_RATE = 0.9

    # Number of reward output
    N_REWARD = 1

    GRADIENT_METHOD = 'sgd'

    model_params = [
        (l.layers.InputLayer, {"shape": (N_BATCH, N_TIME_STEPS, N_INPUT_FEATURES)}),

        (l.layers.LSTMLayer, {"num_units": N_HIDDEN}),

        (l.layers.ReshapeLayer, {"shape": (N_BATCH * N_TIME_STEPS, N_HIDDEN)}),

        (l.layers.DenseLayer, {"num_units": N_OUTPUT_FEATURES, "nonlinearity": T.tensor.tanh}),

        (l.layers.ReshapeLayer, {"shape": (N_BATCH, N_TIME_STEPS, N_OUTPUT_FEATURES)})
    ]

    modle = Model(model_params=model_params)

